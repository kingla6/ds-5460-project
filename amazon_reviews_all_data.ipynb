{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da293775",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f71651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType\n",
    "spark = SparkSession.builder.appName('amazon').getOrCreate()\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"marketplace\",       StringType(),    True), \\\n",
    "    StructField(\"customer_id\",       StringType(),    True), \\\n",
    "    StructField(\"review_id\",         StringType(),    True), \\\n",
    "    StructField(\"product_id\",        StringType(),    True), \\\n",
    "    StructField(\"product_parent\",    StringType(),    True), \\\n",
    "    StructField(\"product_title\",     StringType(),    True), \\\n",
    "    StructField(\"product_category\",  StringType(),    True), \\\n",
    "    StructField(\"star_rating\",       IntegerType(),   True), \\\n",
    "    StructField(\"helpful_votes\",     IntegerType(),   True), \\\n",
    "    StructField(\"total_votes\",       IntegerType(),   True), \\\n",
    "    StructField(\"vine\",              StringType(),    True), \\\n",
    "    StructField(\"verified_purchase\", StringType(),    True), \\\n",
    "    StructField(\"review_headline\",   StringType(),    True), \\\n",
    "    StructField(\"review_body\",       StringType(),    True), \\\n",
    "    StructField(\"review_date\",       TimestampType(), True), \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2269e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'gs://biodata_bucket/archive-5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(path, schema=schema, header=True, sep='\\t', mode='DROPMALFORMED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out missing review titles and bodies\n",
    "data = data.filter(data.review_body.isNotNull())\n",
    "data = data.filter(data.review_headline.isNotNull())\n",
    "data = data.select('product_title', 'star_rating',\n",
    "        'helpful_votes', 'total_votes', 'verified_purchase',\n",
    "        'review_headline', 'review_body', 'product_category')\n",
    "print(data.count())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\"verified_purchase\",data[\"verified_purchase\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('product_category').count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5975a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['multilingual','Apparel','Automotive','Baby','Beauty','Books','Camera','Digital_Ebook_Purchase',\n",
    "         'Digital_Music_Purchase','Digital_Software','Digital_Video_Download','Digital_Video_Games','Electronics',\n",
    "         'Furniture','Gift_Card','Grocery','Health_Personal_Care','Major_Appliances','Mobile_Apps','Mobile_Electronics',\n",
    "         'Music','Musical_Instruments','Office_Products','Outdoors','PC','Personal_Care_Appliances','Pet_Products',\n",
    "         'Shoes','Software','Sports','Tools','Toys','Video_DVD','Video_Games','Video','Watches','Wireless']\n",
    "\n",
    "data = data.filter(data.product_category.isin(categories))\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('product_category').count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0e9e9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, Word2Vec, StringIndexer, VectorAssembler, Normalizer, OneHotEncoder\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "\n",
    "#onehotencoder_v_purch = OneHotEncoder(inputCol=\"verified_purchase\", outputCol=\"ver_purch\")\n",
    "tokenizer_pt = Tokenizer(inputCol='product_title', outputCol='pt_token')\n",
    "tokenizer_rh = Tokenizer(inputCol='review_headline', outputCol='rh_token')\n",
    "tokenizer_rb = Tokenizer(inputCol='review_body', outputCol='rb_token')\n",
    "tokenizer_cat = Tokenizer(inputCol='product_category', outputCol='cat_token')\n",
    "remover_pt = StopWordsRemover(inputCol='pt_token', outputCol='pt_stop')\n",
    "remover_rh = StopWordsRemover(inputCol='rh_token', outputCol='rh_stop')\n",
    "remover_rb = StopWordsRemover(inputCol='rb_token', outputCol='rb_stop')\n",
    "w2v_pt = Word2Vec(vectorSize=3, minCount=0, inputCol=\"pt_stop\", outputCol=\"pt_vec\")\n",
    "w2v_rh = Word2Vec(vectorSize=3, minCount=0, inputCol=\"rh_stop\", outputCol=\"rh_vec\")\n",
    "w2v_rb = Word2Vec(vectorSize=5, minCount=0, inputCol=\"rb_stop\", outputCol=\"rb_vec\")\n",
    "w2v_cat = Word2Vec(vectorSize=1, minCount=0, inputCol=\"cat_token\", outputCol=\"cat_vec\")\n",
    "# labeler = StringIndexer(inputCol='star_rating',outputCol='label', stringOrderType='alphabetAsc')\n",
    "assembler = VectorAssembler(inputCols=['helpful_votes', 'total_votes', 'ver_purch', 'pt_vec', 'rh_vec', 'rb_vec', 'cat_vec'], outputCol='features')\n",
    "normalizer = Normalizer(inputCol='features', outputCol='norm_features')\n",
    "\n",
    "\n",
    "lr = LogisticRegression(featuresCol='norm_features', labelCol='star_rating')\n",
    "dtc = DecisionTreeClassifier(featuresCol='norm_features', labelCol='star_rating')\n",
    "rfc = RandomForestClassifier(featuresCol='norm_features',labelCol='star_rating')\n",
    "\n",
    "# build your pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer_pt, tokenizer_rh, tokenizer_rb, tokenizer_cat,\n",
    "                            remover_pt, remover_rh, remover_rb,\n",
    "                            w2v_pt, w2v_rh, w2v_rb, w2v_cat\n",
    "                            , assembler, normalizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5687c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your pipeline\n",
    "final_data = pipeline.fit(data).transform(data).select('norm_features', 'star_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split your training set into 0.7/0.3 (train/test)\n",
    "train_data, test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe743b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models (its three models, so it might take some time)\n",
    "lr_model = lr.fit(train_data)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1740e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(test_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"star_rating\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "lr_acc = acc_evaluator.evaluate(lr_predictions)\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here are the results!\")\n",
    "print('-'*80)\n",
    "print('A logistic regression classifier had an accuracy of: {0:2.2f}%'.format(lr_acc*100))\n",
    "print('-'*80)\n",
    "print('A single decision tree had an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*80)\n",
    "print('A random forest ensemble had an accuracy of: {0:2.2f}%'.format(rfc_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
